{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Numba for the GPU\n",
    "\n",
    "- [CUDA Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html)\n",
    "\n",
    "- [pyCUDA](https://documen.tician.de/pycuda/) which requires writing C code in python is not tested here\n",
    "\n",
    "__Note__: examples below may not show valuable speedups but their goal is to introduce Numba's syntax\n",
    "\n",
    "## Universal and generalize functions ufuncs/gufuncs\n",
    "\"ufuncs\" operate in an __elementwise__ fashion. Hence, they are suitable for parallelisation.\n",
    "Numba finds the broadcast rules for a defined scalar function of all the inputs.\n",
    "\n",
    "- Ufuncs that involve heavy math operations on large data sets may be suitable for the GPU.\n",
    "- `np` math functions won't work on the device but their `math` counterparts do.\n",
    "- Use `float32` when possible for faster runtime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, vectorize, guvectorize\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# an explicit type signature has to be defined\n",
    "@vectorize(['int64(int64, int64)'], target='cuda')\n",
    "def add_func(x, y):\n",
    "    return x + y\n",
    "\n",
    "print('a+b:\\n', add_func(1, 2))\n",
    "print('a+b:\\n', add_func(2.3, 2)) # implicit cast into int64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Device functions\n",
    "\n",
    "- May be called only from a GPU one.\n",
    "- CUDA compiler inlines device functions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@cuda.jit(device=True) # NO explicit type signature\n",
    "def device_exp(a):\n",
    "    return math.exp(a)\n",
    "\n",
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def function_to_be_compiled(a,b):\n",
    "    return device_exp(a) + device_exp(b)\n",
    "\n",
    "function_to_be_compiled(1,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPU memory\n",
    "It is good to allocate device memory once and refill it with host data in runtime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def add_func(x, y):\n",
    "    return x + y\n",
    "\n",
    "n = 1000000\n",
    "x = np.arange(n).astype(np.float32)\n",
    "y = 2 * x\n",
    "\n",
    "x_device = cuda.to_device(x)\n",
    "y_device = cuda.to_device(y)\n",
    "\n",
    "%timeit add_func(x, y)\n",
    "%timeit add_func(x_device, y_device) # the output is still a numba.cuda.cudadrv.devicearray.DeviceNDArray\n",
    "\n",
    "out_device = cuda.device_array(shape=(n,), dtype=np.float32)  # does not initialize the contents, like np.empty()\n",
    "%timeit add_func(x_device, y_device, out=out_device)\n",
    "%timeit out_host = out_device.copy_to_host()\n",
    "%timeit x_device = cuda.to_device(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generalized functions `gufuncs`\n",
    "\n",
    "- Generalized ufuncs (ufuncs that need to broadcast one of it's inputs) need a signature that shows the index ordering when dealing with multiple inputs.\n",
    "- The last argument of a `gufuncs` is their output array."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# have to include the output array in the type signature\n",
    "# '(n),()->(n)' maps a 1D array and a scalar to 1D array\n",
    "@guvectorize(['(float32[:],float32, float32[:])'], '(n),()->(n)', target='cuda')\n",
    "def cuda_add(x,y, out):\n",
    "    for i in range(x.shape[0]):\n",
    "        out[i] = x[i] + y\n",
    "\n",
    "cuda_add(np.ones(3),1.0)\n",
    "# cuda_add(np.ones(3),1) # TypeError: no matching signature\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "argv": [
    "/home/alameddin/z_nosync_packages/pyenv/versions/3.6.9/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}