# -*- coding: utf-8 -*-
"""SVD_benchmark.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/wangz10/d6f43db76ca260516d149d92b8834bf9/svd_benchmark.ipynb
"""

import numpy as np
import pandas as pd
import scipy.linalg
import scipy.sparse as sp

import jax.numpy as jnp
import jax.scipy as jsp
from jax import random, jit

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set_context('notebook')

import jax, scipy

print('jax version:', jax.__version__)
print('numpy version:', np.__version__)
print('scipy version:', scipy.__version__)

np.show_config()

# @ref: https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow
from tensorflow.python.client import device_lib

def get_available_gpus():
    local_device_protos = device_lib.list_local_devices()
    return [x.name for x in local_device_protos if x.device_type == 'GPU']

get_available_gpus()

"""# JAX demo"""

def slow_f(x):
  # Element-wise ops see a large benefit from fusion
  return x * x + x * 2.0

# use XLA to compile the function
fast_f = jit(slow_f)

x = np.ones((5000, 5000))
type(x) # numpy.ndarray

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# fast_f(x)

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# slow_f(x)

x_j = jnp.ones((5000, 5000))
type(x_j)

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# fast_f(x_j)

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# slow_f(x_j)

"""# Full SVD for dense matrix"""

def jnp_svd(X):
    # Compute full SVD
    U, Sigma, Vh = jnp.linalg.svd(X,
                                  full_matrices=False, # It's not necessary to compute the full matrix of U or V
                                  compute_uv=True,
                                 )
    return U, Sigma, Vh

def jsp_svd(X):
    U, Sigma, Vh = jsp.linalg.svd(X,
                                  full_matrices=False,
                                  compute_uv=True,
                                  check_finite=False,
                                  overwrite_a=True
                                 )
    return U, Sigma, Vh


def np_svd(X):
    U, Sigma, Vh = np.linalg.svd(X,
                                 full_matrices=False,
                                 compute_uv=True
                                )
    return U, Sigma, Vh

def scipy_svd(X):
    U, Sigma, Vh = scipy.linalg.svd(X,
                                    full_matrices=False,
                                    compute_uv=True,
                                    check_finite=False,
                                    overwrite_a=True
                                )
    return U, Sigma, Vh

def scipy_gesvd(X):
    U, Sigma, Vh = scipy.linalg.svd(X,
                                    full_matrices=False,
                                    compute_uv=True,
                                    check_finite=False,
                                    overwrite_a=True,
                                    lapack_driver='gesvd'
                                )
    return U, Sigma, Vh

from time import time

def time_func(func, n_trials, *args, **kwargs):
    times = []
    for i in range(n_trials):
        t0 = time()
        res = func(*args, **kwargs)
        tt = time()
        t = tt - t0
        times.append(t)
    return np.asarray(times)

def time_svd_funcs(funcs, Ns=[200, 500, 1000, 2000], n_trials=7):
    results = []
    key = random.PRNGKey(42)
    for N in Ns:
        # generate random matrix as input
        X = random.normal(key, (N, N))
        for func in funcs:
            times = time_func(func, n_trials, X)

            results.extend([{
                'time': t,
                'N': N,
                'func_name': func.__name__,
                } for t in times])
    return pd.DataFrame(results)

results = time_svd_funcs([np_svd, scipy_svd, scipy_gesvd],
                         Ns=[200, 500, 1000, 2000]
                        )

results.shape

results.groupby(['N', 'func_name']).agg([np.mean, np.std])

ax = sns.lineplot(x='N', y='time', hue='func_name',
                  marker='o',
                  data=results)
ax.set_ylabel('Time (seconds)')
ax.set_xlabel('$n$')
ax.set_yscale('log')
# ax.set_xscale('log')



results = time_svd_funcs([jnp_svd, jsp_svd,
                          np_svd, scipy_svd
                         ],
                         Ns=[200, 500, 1000, 2000]
                        )

results.groupby(['N', 'func_name']).agg([np.mean, np.std])

ax = sns.lineplot(x='N', y='time', hue='func_name',
                  marker='o',
                  data=results)
ax.set_ylabel('Time (seconds)')
ax.set_xlabel('$n$')
ax.set_yscale('log')

# Compute jax function with JIT
jit_jnp_svd = jit(jnp_svd)
jit_jsp_svd = jit(jsp_svd)

def time_svd(svd_func, n_trials=7, N=200):
    times = []
    for i in range(n_trials):
        # generate a random input matrix every trail to prevent
        # jax from caching the results
        key = random.PRNGKey(np.random.randint(0, 1000))
        X = random.normal(key, (N, N))
        t0 = time()
        res = svd_func(X)
        tt = time()
        t = tt - t0
        times.append(t)
    return np.asarray(times)

def time_svd_funcs2(funcs, Ns=[200, 500, 1000, 2000], n_trials=7):
    results = []

    for N in Ns:
        for func in funcs:
            times = time_svd(func, n_trials, N)
            results.extend([{
                'time': t,
                'N': N,
                'func_name': func.__name__,
                } for t in times])
    return pd.DataFrame(results)



results = time_svd_funcs2([jnp_svd, jsp_svd,
                           np_svd, scipy_svd
                         ],
                         Ns=[200, 500, 1000, 2000]
                        )

results.groupby(['N', 'func_name']).agg([np.mean, np.std])

ax = sns.lineplot(x='N', y='time', hue='func_name',
                  style='func_name',
                  marker='o',
                  alpha=0.7,
                  data=results)
ax.set_ylabel('Time (seconds)')
ax.set_xlabel('$n$')
ax.set_yscale('log')
